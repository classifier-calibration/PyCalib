{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting reliability diagrams\n\nThis example illustrates how to visualise the reliability diagram for a binary\nprobabilistic classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Miquel Perello Nieto <miquel.perellonieto@bristol.ac.uk>\n# License: new BSD\n\nprint(__doc__)\nSAVEFIGS=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example shows different ways to visualise the reliability diagram for a\nbinary classification problem.\n\nFirst we will generate two synthetic models and some synthetic scores and\nlabels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nnp.random.seed(42)\n\nn_c1 = n_c2 = 200\np = np.concatenate((np.random.beta(2, 5, n_c1),\n                    np.random.beta(4, 3, n_c2)\n                   ))\n\ny = np.concatenate((np.zeros(n_c1), np.ones(n_c2)))\n\nprint(p.shape)\nprint(y.shape)\n\ns1 = 1/(1 + np.exp(-3*(p - 0.5)))\ns2 = 1/(1 + np.exp(-8*(p - 0.5)))\n\nplt.scatter(s1, p, label='Model 1')\nplt.scatter(s2, p, label='Model 2')\nplt.scatter(p, y)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlabel('Model scores')\nplt.ylabel('Sample true probability')\nplt.grid()\nplt.legend()\n\np = np.vstack((1 - p, p)).T\ns1 = np.vstack((1 - s1, s1)).T\ns2 = np.vstack((1 - s2, s2)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A perfect calibration should be as follows, compared with the generated\nscores\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n\np_g_p = stats.beta.pdf(x=p[:, 1], a=3, b=2)\np_g_n = stats.beta.pdf(x=p[:, 1], a=2, b=7)\n\np_hat = p_g_p/(p_g_n+p_g_p)\np_hat = np.vstack((1 - p_hat, p_hat)).T\n\nplt.scatter(p[:, 1], s1[:, 1], label='Model 1')\nplt.scatter(p[:, 1], s2[:, 1], label='Model 2')\nplt.scatter(p[:, 1], p_hat[:, 1], color='red', label='Bayes optimal correction')\nplt.xlabel('Sample true probability')\nplt.ylabel('Model scores')\nplt.grid()\nplt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we can show the most common form to visualise a reliability diagram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pycalib.visualisations import plot_reliability_diagram\n\nfig = plot_reliability_diagram(labels=y, scores_list=[s1, ],\n                               legend=['Model 1'],\n                               class_names=['Negative', 'Positive'])\nif SAVEFIGS:\n    fig.savefig('fig1.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can enable some parameters to show several aspects of the reliability\ndiagram. For example, we can add a histogram indicating the number of samples\non each bin (or show the count in each marker), the correction that should be\napplied to the average scores in order to calibrate the model can be also\nshown as red arrows pointing to the direction of the diagonal (perfectly\ncalibrated model). And even the true class of each sample at the y\ncoordinates [0 and 1] for each scored instance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pycalib.visualisations import plot_reliability_diagram\n\nfig = plot_reliability_diagram(labels=y, scores_list=[s1, ],\n                               legend=['Model 1'],\n                               show_histogram=True,\n                               bins=9, class_names=['Negative', 'Positive'],\n                               show_counts=True,\n                               show_correction=True,\n                               show_samples=True,\n                               sample_proportion=1.0,\n                               hist_per_class=True)\nif SAVEFIGS:\n    fig.savefig('fig2.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It can be also useful to have 95% confidence intervals for each bin by\nperforming a binomial proportion confidence interval with various statistical\ntests. This function uses https://www.statsmodels.org/stable/generated/statsmodels.stats.proportion.proportion_confint.html\nthus accepts the different tests available in the statsmodels library. In the\nfollowing example we use the Clopper-Pearson interval based on Beta\ndistribution and a confidence interval of 95%.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plot_reliability_diagram(labels=y, scores_list=[s2, ],\n                               legend=['Model 2'],\n                               show_histogram=False,\n                               show_counts=True,\n                               bins=13, class_names=['Negative', 'Positive'],\n                               show_samples=True, sample_proportion=1.0,\n                               errorbar_interval=0.95,\n                               interval_method='beta',)\nif SAVEFIGS:\n    fig.savefig('fig3.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function also allows the visualisation of multiple models for comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plot_reliability_diagram(labels=y, scores_list=[s1, s2],\n                               legend=['Model 1', 'Model 2'],\n                               show_histogram=True,\n                               bins=10, class_names=['Negative', 'Positive'],\n                               errorbar_interval=0.95,\n                               interval_method='beta')\nif SAVEFIGS:\n    fig.savefig('fig4.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is possible to draw reliability diagram for multiple classes as well. In\nthis case we will just assign 1/3 of the samples to a 3rd class, will\ngive the same scores as some of the other classes, and normalise them to sum\nto one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class_2_idx = range(int(len(y)/3), int(2*len(y)/3))\ny[class_2_idx] = 2\ns1 = np.hstack((s1, s1[:, 1].reshape(-1, 1)))\ns1[class_2_idx,2] *= 3\ns1 /= s1.sum(axis=1)[:, None]\ns2 = np.hstack((s2, s2[:, 1].reshape(-1, 1)))\ns2[class_2_idx,2] *= 2\n\nfig = plot_reliability_diagram(labels=y, scores_list=[s1, s2],\n                               legend=['Model 1', 'Model 2'],\n                               show_histogram=True,\n                               )\nif SAVEFIGS:\n    fig.savefig('fig5.png')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}